## ğŸ“– Definition
- Markov Decision Process(MDP) : Markov propertyë¥¼ ë”°ë¥´ëŠ” ranodm process.
## ğŸ“ Key Concepts

## ğŸ“Œ Important Points

## ğŸ§© Examples / Use-cases


```python
# Example code snippet
```

## ğŸ—ƒï¸ Related Topics

- [[Related topic 1]]
    
- [[Related topic 2]]    

## â“ Common Questions

## ğŸ§  Summary in One Sentence

## ğŸ“… Dates

- First studied: 2025-04-01
    
- Last reviewed:
    

## ğŸ·ï¸ Tags

#ComputerScience #Theory #Study 