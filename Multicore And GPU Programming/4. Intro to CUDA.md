GPU : minimize the branch(if-else)

### CPU vs GPU
The # of cores : GPU(small cores) > CPU (SM, SC)
GPU : L3 cache 없음
Memory size : CPU > GPU
Memory (Transfer) Bandwidth : GPU > CPU
GPU has scratchpad(memory) : L1 cache turn on/off (consider default setting)
	turn off : L1 cache is not useful (parallel programming x)
4X # of cores
PCI-e

Saving data in both memory space(share memory btw CPU, GPU)
How many 
2 different memory allocation API
- Allocating memory in CPU DRAM
- For memory space in GPU DRAM (cudamalloc)
Synchronization
- Manually update GPU DRAM data by using cuda specific apis.
- Add explicit data transfer